{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac681b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "from langchain_community.document_loaders import (\n",
    "    WebBaseLoader, \n",
    "    PyPDFLoader, \n",
    "    Docx2txtLoader,\n",
    ")\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "#from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI, AzureOpenAI\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "342f3c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure OpenAI configured successfully!\n"
     ]
    }
   ],
   "source": [
    "# Configure Azure OpenAI Embeddings\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT_NAME\"),\n",
    "    openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# Configure Azure OpenAI Chat Model\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"),\n",
    "    openai_api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"Azure OpenAI configured successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d32365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load docs\n",
    "\n",
    "doc_paths = [\n",
    "    \"./docs/test_rag.docx\",\n",
    "    \"./docs/test_rag.pdf\",\n",
    "]\n",
    "\n",
    "docs = [] \n",
    "for doc_file in doc_paths:\n",
    "    file_path = Path(doc_file)\n",
    "\n",
    "    try:\n",
    "        if doc_file.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif doc_file.endswith(\".docx\"):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        elif doc_file.endswith(\".txt\") or doc_file.endswith(\".md\"):\n",
    "            loader = TextLoader(file_path)\n",
    "        else:\n",
    "            print(f\"Document type {doc_file} not supported.\")\n",
    "            continue\n",
    "\n",
    "        docs.extend(loader.load())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading document {doc_file}: {e}\")\n",
    "\n",
    "\n",
    "# Load URLs\n",
    "\n",
    "url = \"https://docs.streamlit.io/develop/quick-reference/release-notes\"\n",
    "try:\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs.extend(loader.load())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading document from {url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3b03cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'docs\\\\test_rag.docx'}, page_content='My favorite food is margarita pizza.\\n\\n\\n\\nThere are 47588 bottles in the truck.'),\n",
       " Document(metadata={'producer': 'Microsoft¬Æ Word for Microsoft 365', 'creator': 'Microsoft¬Æ Word for Microsoft 365', 'creationdate': '2024-09-15T19:40:36+02:00', 'msip_label_1cf2ba15-c468-47c8-b178-cba8acf110ec_siteid': 'eb25818e-5bd5-49bf-99de-53e3e7b42630', 'msip_label_1cf2ba15-c468-47c8-b178-cba8acf110ec_method': 'Standard', 'msip_label_1cf2ba15-c468-47c8-b178-cba8acf110ec_enabled': 'True', 'author': 'Domingo Dom√®nech Enric (ERNI)', 'moddate': '2024-09-15T19:40:36+02:00', 'source': 'docs\\\\test_rag.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='My favorite food is margarita pizza. \\nThere are 47588 bottles in the truck.'),\n",
       " Document(metadata={'source': 'https://docs.streamlit.io/develop/quick-reference/release-notes', 'title': 'Release notes - Streamlit Docs', 'description': 'A changelog of highlights and fixes for each version of Streamlit.', 'language': 'No language found.'}, page_content='Release notes - Streamlit DocsDocumentationsearchSearchrocket_launchGet startedInstallationaddFundamentalsaddFirst stepsaddcodeDevelopConceptsaddAPI referenceaddTutorialsaddQuick referenceremoveCheat sheetRelease notesremove2025202420232022202120202019Pre-release featuresRoadmapopen_in_newweb_assetDeployConceptsaddStreamlit Community CloudaddSnowflakeOther platformsaddschoolKnowledge baseFAQInstalling dependenciesDeployment issuesHome/Develop/Quick reference/Release notesRelease notes\\nThis page lists highlights, bug fixes, and known issues for the latest release of Streamlit. If you\\'re looking for information about nightly releases or experimental features, see Pre-release features.\\nUpgrade Streamlit\\nstarTipTo upgrade to the latest version of Streamlit, run:pip install --upgrade streamlit\\n\\nVersion 1.47.0 (latest)\\nRelease date: July 16, 2025\\nHighlights\\n\\nüé®\\xa0Streamlit has additional theming configuration options!\\n\\ntheme.baseFontWeight: Set the root font weight of text in the app.\\ntheme.chartCategoricalColors: Configure default categorical colors for Plotly, Altair, and Vega-Lite charts.\\ntheme.chartSequentialColors: Configure default sequential colors for Plotly, Altair, and Vega-Lite charts.\\ntheme.codeFontWeight: Set the font weight of code text.\\ntheme.dataframeHeaderBackgroundColor: Set the background color of dataframe headers.\\ntheme.headingFontSizes: Set the font sizes of headings.\\ntheme.headingFontWeights: Set the font weights of headings.\\ntheme.linkUnderline: Configure whether to underline links.\\n\\n\\n\\nNotable Changes\\n\\nüí¨\\xa0You can set the unsubmitted value of st.chat_input through Session State (#10175, #7166).\\n‚ÜîÔ∏è\\xa0You can set a width parameter for st.html, st.feedback, st.pills, st.segmented_control, and st.multiselect.\\n‚ÜïÔ∏è\\xa0You can set a height parameter for st.metric and st.text_area.\\nüë©\\u200düíª\\xa0st.code and st.form can have height=\"stretch\".\\nüßë\\u200düíª\\xa0st.code can have width=\"content\".\\n‚è±Ô∏è\\xa0You can show the elapsed time with the spinner for cached functions using the show_time parameter (#11469, #10647). Thanks, Darkace01!\\nserver.showEmailPrompt lets you configure whether to show the email prompt (for locally running apps).\\nüíæ\\xa0NumberColumn and ProgressColumn support \"bytes\" as a predefined format (#11288, #11287). Thanks, cgivre!\\n‚öôÔ∏è\\xa0Column configuration accepts pixel widths for columns (#11838).\\n‚ÑπÔ∏è\\xa0The display_text parameter of LinkColumn accepts a Material icon (#11690, #7004).\\nüñäÔ∏è\\xa0The title parameter of st.dialog accepts Markdown (#11763, #11755).\\nüß©\\xa0To support proxying requests for custom components, in declare_component, you can set both url and path (#11698).\\n\\nOther Changes\\n\\nüß≠\\xa0Section labels in the sidebar navigation widget are collapsible (#11863).\\nüìÇ\\xa0The \"Deploy\" button is hidden when the \"File change\" notification is visible in the app chrome (#11834).\\nüîù\\xa0When using top navigation in an app, the header has more padding (#11836).\\nü™ú\\xa0In NumberColumn, the precision from step will override the display precision from format, unless format is a printf string (#11835).\\nüìÖ\\xa0When st.date_input accepts a date range, the widget displays a quick-select option below the calendar for common date ranges (#10166, #11108).\\nüèãÔ∏è\\xa0Dataframes support font weight defined in pandas Styler objects (#11705, #6461).\\nü´•\\xa0The about dialog does not show by default in the app menu. The current Streamlit version is displayed in the settings dialog (#10091).\\nüíÖ\\xa0st.metric uses a background color for the delta value, like st.badge (#11678).\\nüíª\\xa0IDEs can give type hints for .clear() on cached functions (#11793, #11821). Thanks, whitphx!\\nüîÑ\\xa0Bug swap: To prevent a multipage app regression, st.context.theme does not automatically rerun the app on first load. In some cases, st.context.theme may not be correct until the first rerun (#11870, #11797).\\nüßπ\\xa0Bug fix: st.chat_input displays correctly at the bottom of the screen in mobile view (#11896, #11722, #11891).\\n‚è≥\\xa0Bug fix: When a WebSocket reconnects, the app will fully rerun to prevent missing fragments (#11890, #11660).\\nü™±\\xa0Bug fix: To reduce No such file or directory errors, the file watcher has more robust exception handling and clearer logging (#11871, #11841, #11809, #11728).\\nüí©\\xa0Bug fix: Vega-Lite facet charts do not flicker (#11833).\\n‚ò†Ô∏è\\xa0Bug fix: When the initial sidebar state is set to \"collapsed\", the sidebar correctly loads in a collapsed state without flickering open (#11861, #11848).\\nüëΩ\\xa0Bug fix: To prevent apps from being out of sync with their current code at a later time, Streamlit clears the script cache when all file watchers disconnect (#11876, #11739). Thanks, diwu-sf!\\nüëª\\xa0Bug fix: Inline code in tooltips has the same relative size as inline code in other Markdown text (#11877).\\nü¶Ä\\xa0Bug fix: st.multiselect and st.selectbox display the correct placeholder text when accept_new_options=True (#11623, #11609).\\nü¶ã\\xa0Bug fix: The column visibility menu can be closed by toggling the toolbar icon (#11857, #11801).\\nü¶é\\xa0Bug fix: Progress bar columns in dataframes have the correct padding between the bar and its label (#11685).\\nüêå\\xa0Bug fix: The warning indicator in a dataframe cell adapts to theme configuration (#11682).\\nüï∏Ô∏è\\xa0Bug fix: To fix multiple visual and UX bugs in dataframe, glide-data-grid was updated (#11677, #8310, #9498, #9471).\\nü¶ó\\xa0Bug fix: In the sidebar navigation widget, font spacing and weight were adjust for visual clarity (#11814).\\nü¶Ç\\xa0Bug fix: Altair charts correctly resize in width to match their container (#11807, #11802).\\nü¶ü\\xa0Bug fix: The running-man icon matches the theme configuration (#11461, #11371). Thanks, TreavVasu!\\nü¶†\\xa0Bug fix: The top header background is correctly opaque when it contains elements (#11787, #11785).\\nü™∞\\xa0Bug fix: Extra top padding is removed when printing (#11798).\\nü™≥\\xa0Bug fix: Markdown inline code displays correctly when unsafe_allow_html=True (#11817, #11800). Thanks, bajajku!\\nüï∑Ô∏è\\xa0Bug fix: The WebSocket ping interval does not exceed the timeout interval (#11693, #11670).\\nüêû\\xa0Bug fix: The sidebar state initialized correctly on Community Cloud and page content slides and resizes correctly in response to the sidebar (#11732, #11702, #11710).\\nüêù\\xa0Bug fix: The timer in st.spinner uses system time to prevent pausing when the user focuses on another browser tab (#11756, #11720).\\nüêú\\xa0Bug fix: Empty containers with borders and empty expanders are visible before elements are added to them (#11669).\\nü™≤\\xa0Bug fix: st.audio_input and st.camera_input have consistent appearances (#11699, #11700).\\nüêõ\\xa0Bug fix: To prevent a race condition, the file watcher correctly applies a lock to watched paths (#11692, #11691).\\n\\nOlder versions of Streamlit\\n\\n2025 release notes\\n2024 release notes\\n2023 release notes\\n2022 release notes\\n2021 release notes\\n2020 release notes\\n2019 release notes\\nPrevious: Cheat sheetNext: 2025forumStill have questions?Our forums are full of helpful information and Streamlit experts.HomeContact UsCommunity¬© 2025 Snowflake Inc.Cookie policyforum Ask AI')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b648ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split docs\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=5000,\n",
    "    chunk_overlap=1000,\n",
    ")\n",
    "\n",
    "document_chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05e6564a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and load the documents to the vector store\n",
    "\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=document_chunks,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe2e07a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint: https://ai-openai-live-swc-01.openai.azure.com\n",
      "API Key: 1gNzGehp ...\n",
      "Deployment Name: gpt-4o\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Endpoint:\", os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "print(\"API Key:\", os.getenv(\"AZURE_OPENAI_API_KEY\")[:8], \"...\")\n",
    "print(\"Deployment Name:\", os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "073ff3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "\n",
    "def _get_context_retriever_chain(vector_db, llm):\n",
    "    retriever = vector_db.as_retriever()\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        (\"user\", \"Given the above conversation, generate a search query to look up in order to get inforamtion relevant to the conversation, focusing on the most recent messages.\"),\n",
    "    ])\n",
    "    retriever_chain = create_history_aware_retriever(llm, retriever, prompt)\n",
    "\n",
    "    return retriever_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d630c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversational_rag_chain(llm):\n",
    "    retriever_chain = _get_context_retriever_chain(vector_db, llm)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "        \"\"\"You are a helpful assistant. You will have to answer to user's queries.\n",
    "        You will have some context to help with your answers, but now always would be completely related or helpful.\n",
    "        You can also use your knowledge to assist answering the user's queries.\\n\n",
    "        {context}\"\"\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ])\n",
    "    stuff_documents_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "    return create_retrieval_chain(retriever_chain, stuff_documents_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c806c931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latest version of Streamlit is 1.47.0, released on July 16, 2025."
     ]
    }
   ],
   "source": [
    "# Augmented Generation\n",
    "\n",
    "# llm_stream_openai = AzureChatOpenAI(\n",
    "#     model=\"gpt-4o\",  # Here you could use \"o1-preview\" or \"o1-mini\" if you already have access to them\n",
    "#     temperature=0.3,\n",
    "#     streaming=True,\n",
    "# )\n",
    "\n",
    "llm_stream_openai = AzureChatOpenAI(\n",
    "    model=\"gpt-4o\",  # or your deployed model name\n",
    "    temperature=0.3,\n",
    "    streaming=True,\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),  # or just \"2023-12-01-preview\"\n",
    "    openai_api_type=\"azure\",\n",
    ")\n",
    "\n",
    "llm_stream = llm_stream_openai  # Select between OpenAI and Anthropic models for the response\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hi\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi there! How can I assist you today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the latest version of Streamlit?\"},\n",
    "]\n",
    "messages = [HumanMessage(content=m[\"content\"]) if m[\"role\"] == \"user\" else AIMessage(content=m[\"content\"]) for m in messages]\n",
    "\n",
    "conversation_rag_chain = get_conversational_rag_chain(llm_stream)\n",
    "response_message = \"*(RAG Response)*\\n\"\n",
    "for chunk in conversation_rag_chain.pick(\"answer\").stream({\"messages\": messages[:-1], \"input\": messages[-1].content}):\n",
    "    response_message += chunk\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": response_message})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ram_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
